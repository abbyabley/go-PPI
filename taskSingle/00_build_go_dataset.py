import pandas as pd
import requests
import pickle
import os
import time
from tqdm import tqdm
from collections import Counter, defaultdict

# ================= ğŸ”§ è·¯å¾„é…ç½® =================
# å‡†ç¡®ä½¿ç”¨ä½ åˆ’åˆ†å¥½çš„ DeepPPISP æ•°æ®é›†
CSV_FILES = [
    './Task_Single_dataset/Task_DeepPPISP/352_name_seq_label.csv',
    './Task_Single_dataset/Task_DeepPPISP/Test_70.csv',
]

BASE_DIR = '/home/dongshali/fasta_data'
os.makedirs(f'{BASE_DIR}/meta_data', exist_ok=True)
GO_MAP_SAVE = f'{BASE_DIR}/meta_data/go_mapping.pkl'
NUM_GO_CLASSES = 150 
# ===============================================

def clean_to_pdb_id(raw_name):
    """
    ã€æ ¸å¿ƒä¿®å¤ã€‘ï¼šä¸ç®¡æ˜¯æœ‰ä¸‹åˆ’çº¿(1F60_A)ã€è¿å†™(1F60A)è¿˜æ˜¯ç ´æŠ˜å·(1F60-A)ï¼Œ
    åªè¦å»æ‰ > ä¹‹åï¼ŒPDB ID æ°¸è¿œæ˜¯å‰ 4 ä¸ªå­—ç¬¦ï¼
    """
    name_str = str(raw_name).strip().lstrip('>')
    return name_str[:4].upper()

def get_go_terms_from_rcsb(pdb_id):
    """é€šè¿‡ RCSB PDB å®˜æ–¹ REST API è·å– GO æ³¨é‡Š"""
    go_terms = set()
    entry_url = f"https://data.rcsb.org/rest/v1/core/entry/{pdb_id}"
    try:
        resp = requests.get(entry_url, timeout=10)
        if resp.status_code != 200:
            return go_terms
            
        data = resp.json()
        entity_ids = data.get('rcsb_entry_container_identifiers', {}).get('polymer_entity_ids', [])
    except Exception:
        return go_terms

    for ent_id in entity_ids:
        entity_url = f"https://data.rcsb.org/rest/v1/core/polymer_entity/{pdb_id}/{ent_id}"
        try:
            ent_resp = requests.get(entity_url, timeout=10)
            if ent_resp.status_code == 200:
                annotations = ent_resp.json().get('rcsb_polymer_entity_annotation', [])
                for anno in annotations:
                    if anno.get('type') == 'GO':
                        go_id = anno.get('annotation_id')
                        if go_id:
                            go_terms.add(go_id)
        except Exception:
            continue

    return go_terms

def main():
    print(">>> 1. æ­£åœ¨è¯»å–ä½ åˆ’åˆ†å¥½çš„ DeepPPISP æ•°æ®é›†...")
    raw_names = set()
    for f in CSV_FILES:
        if not os.path.exists(f):
            print(f"âš ï¸ æ‰¾ä¸åˆ°æ–‡ä»¶: {f}")
            continue
        df = pd.read_csv(f)
        # è·å–ç¬¬ä¸€åˆ—çš„æ‰€æœ‰è›‹ç™½è´¨åç§°
        protein_col = df.columns[0] 
        names = df[protein_col].tolist()
        raw_names.update(names)
        
    raw_names = list(raw_names)
    print(f"âœ… å…±è·å–åˆ° {len(raw_names)} ä¸ªå”¯ä¸€çš„è›‹ç™½è´¨å®ä½“ï¼ˆåŒ…å«ä¸åŒé“¾ï¼‰ã€‚")
    
    print(f"\n>>> 2. æ­£åœ¨é€šè¿‡ RCSB PDB å®˜æ–¹ API æ‰’å–çœŸå® GO æ ‡ç­¾...")
    raw_go_dict = defaultdict(set)
    
    for raw_name in tqdm(raw_names, desc="Fetching GO"):
        # æš´åŠ›æˆªå–å‰ 4 ä½ä½œä¸º PDB ID
        pdb_id = clean_to_pdb_id(raw_name)
        
        go_set = get_go_terms_from_rcsb(pdb_id)
        if go_set:
            # æ³¨æ„ï¼šå­˜å…¥å­—å…¸çš„é”®å¿…é¡»æ˜¯åŸå§‹åç§°ï¼ˆå»æ‰ > ï¼‰ï¼Œä»¥ä¿è¯åç»­ Dataset èƒ½ç²¾å‡†åŒ¹é…
            clean_raw_name = str(raw_name).strip().lstrip('>')
            raw_go_dict[clean_raw_name].update(go_set)
            
        time.sleep(0.1)

    print(f"âœ… æˆåŠŸè·å– {len(raw_go_dict)} ä¸ª PDB ç»“æ„çš„ GO æ ‡ç­¾ï¼")

    if len(raw_go_dict) == 0:
        print("âŒ æœªè·å–åˆ°ä»»ä½•æ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œã€‚")
        return

    print("\n>>> 3. æ­£åœ¨ç»Ÿè®¡å¹¶ç­›é€‰é«˜é¢‘ GO åŠŸèƒ½...")
    all_go_terms = []
    for go_set in raw_go_dict.values():
        all_go_terms.extend(list(go_set))
        
    go_counter = Counter(all_go_terms)
    actual_num_classes = min(NUM_GO_CLASSES, len(go_counter))
    top_go = [go for go, count in go_counter.most_common(actual_num_classes)]
    
    go_to_idx = {go_id: idx for idx, go_id in enumerate(top_go)}
    
    final_mapping = {}
    for clean_raw_name, go_set in raw_go_dict.items():
        indices = [go_to_idx[go] for go in go_set if go in go_to_idx]
        if indices: 
            final_mapping[clean_raw_name] = indices
            
    save_data = {
        'go_to_idx': go_to_idx,
        'mapping': final_mapping,
        'num_classes': actual_num_classes
    }
    with open(GO_MAP_SAVE, 'wb') as f:
        pickle.dump(save_data, f)
        
    print(f"âœ… Top-{actual_num_classes} GO æ˜ å°„å­—å…¸å·²ä¿å­˜è‡³: {GO_MAP_SAVE}")
    print("ğŸ‰ ç¬¬ 0 æ­¥æ•°æ®å‡†å¤‡å®Œç¾æ”¶å®˜ï¼ä¸éœ€è¦å†é‡æ–°åˆ‡åˆ†æ•°æ®ï¼Œç›´æ¥æ‹¿ä½ çš„ CSV è¿› DataLoader å³å¯ï¼")

if __name__ == '__main__':
    main()