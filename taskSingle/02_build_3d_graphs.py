import os
import pandas as pd
import requests
import time
import torch
import numpy as np
from tqdm import tqdm
from scipy.spatial import distance_matrix
from Bio.PDB import PDBParser
import warnings
from Bio import BiopythonWarning

# å¿½ç•¥ Biopython è§£æéæ ‡å‡† PDB æ—¶äº§ç”Ÿçš„è­¦å‘Š
warnings.simplefilter('ignore', BiopythonWarning)

# ================= ğŸ”§ è·¯å¾„é…ç½® =================
BASE_DIR = '/home/dongshali/fasta_data'
CSV_FILES = [
    './Task_Single_dataset/Task_DeepPPISP/352_name_seq_label.csv',
    './Task_Single_dataset/Task_DeepPPISP/Test_70.csv'
]
PDB_DIR = f'{BASE_DIR}/pdb_files'
ADJ_DIR = f'{BASE_DIR}/graph_adj_features' # ä¿å­˜æ„å»ºå¥½çš„é‚»æ¥çŸ©é˜µ
os.makedirs(PDB_DIR, exist_ok=True)
os.makedirs(ADJ_DIR, exist_ok=True)

def download_pdb(pdb_id, save_path, retries=3):
    """ä» RCSB PDB ä¸‹è½½æ–‡ä»¶ï¼ŒåŒ…å«é‡è¯•æœºåˆ¶"""
    url = f"https://files.rcsb.org/download/{pdb_id.lower()}.pdb"
    for attempt in range(retries):
        try:
            resp = requests.get(url, timeout=10)
            if resp.status_code == 200:
                with open(save_path, 'w') as f:
                    f.write(resp.text)
                return True
        except requests.exceptions.RequestException:
            time.sleep(1)
    return False

def extract_ca_adjacency(pdb_path, threshold=8.0):
    """è§£æ PDBï¼Œæå–ç¬¬ä¸€æ¡é“¾çš„ CA åŸå­åæ ‡ï¼Œæ„å»ºé‚»æ¥çŸ©é˜µ"""
    parser = PDBParser()
    structure = parser.get_structure('protein', pdb_path)
    
    # é»˜è®¤æå–ç¬¬ä¸€ä¸ª Model çš„ç¬¬ä¸€æ¡ Chain
    first_model = next(structure.get_models())
    first_chain = next(first_model.get_chains())
    
    ca_coords = []
    for residue in first_chain:
        # è·³è¿‡æ°´åˆ†å­ç­‰éæ ‡å‡†æ°¨åŸºé…¸
        if residue.id[0] != ' ': continue 
        if 'CA' in residue:
            ca_coords.append(residue['CA'].get_coord())
            
    if not ca_coords:
        return None
        
    coords_array = np.array(ca_coords)
    # è®¡ç®—æ‰€æœ‰ CA åŸå­ä¸¤ä¸¤ä¹‹é—´çš„æ¬§æ°è·ç¦»
    dist_mat = distance_matrix(coords_array, coords_array)
    # æ„å»ºé‚»æ¥çŸ©é˜µï¼šè·ç¦» < 8Ã… ä¸º 1ï¼ˆåŒ…å«è‡ªç¯ï¼‰ï¼Œå¦åˆ™ä¸º 0
    adj_mat = (dist_mat < threshold).astype(np.float32)
    return torch.tensor(adj_mat)

def main():
    print(">>> 1. æ­£åœ¨è¯»å–è›‹ç™½è´¨åºåˆ—åˆ—è¡¨...")
    raw_names = set()
    for f in CSV_FILES:
        if not os.path.exists(f): continue
        df = pd.read_csv(f)
        names = df.iloc[:, 0].apply(lambda x: str(x).strip().lstrip('>')).tolist()
        raw_names.update(names)
        
    print(f"âœ… å…±è·å–åˆ° {len(raw_names)} ä¸ªå¾…å¤„ç†è›‹ç™½è´¨ã€‚")
    
    success_count = 0
    for name in tqdm(raw_names, desc="Building 3D Graphs"):
        pdb_id = name[:4] # æå–å‰ 4 ä½ä½œä¸ºæ ‡å‡† PDB ID
        pdb_path = os.path.join(PDB_DIR, f"{name}.pdb")
        adj_path = os.path.join(ADJ_DIR, f"{name}.pt")
        
        # 1. ä¸‹è½½ PDB (å¦‚æœä¸å­˜åœ¨)
        if not os.path.exists(pdb_path):
            if not download_pdb(pdb_id, pdb_path):
                continue # ä¸‹è½½å¤±è´¥ï¼Œè·³è¿‡
                
        # 2. æ„å»ºå›¾é‚»æ¥çŸ©é˜µå¹¶ä¿å­˜ (å¦‚æœä¸å­˜åœ¨)
        if not os.path.exists(adj_path):
            try:
                adj_tensor = extract_ca_adjacency(pdb_path)
                if adj_tensor is not None:
                    torch.save(adj_tensor, adj_path)
                    success_count += 1
            except Exception as e:
                continue # æ ¼å¼æŸåæˆ–è§£æå¤±è´¥ï¼Œè·³è¿‡
        else:
            success_count += 1
            
    print(f"\nğŸ‰ ç©ºé—´é‚»æ¥çŸ©é˜µæ„å»ºå®Œæˆï¼æˆåŠŸå¤„ç†: {success_count} / {len(raw_names)}")
    print(f"ğŸ“ çŸ©é˜µæ–‡ä»¶ä¿å­˜åœ¨: {ADJ_DIR}")

if __name__ == '__main__':
    main()